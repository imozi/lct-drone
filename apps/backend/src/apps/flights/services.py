"""
–°–µ—Ä–≤–∏—Å—ã –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –ø–æ–ª–µ—Ç–∞–º–∏ –ë–ê–°.
–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è.
"""

import asyncio
import logging
import re
from datetime import datetime, time, timedelta
from typing import TYPE_CHECKING, Any, Optional

import pytz

if TYPE_CHECKING:
    from .models import RussianRegion
from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor, as_completed

import pandas as pd
from django.contrib.gis.geos import Point
from django.core.exceptions import ValidationError
from django.db import connection, transaction
from django.utils import timezone

from .models import (
    ActualFlight,
    DroneOperator,
    DroneType,
    FlightPlan,
    FlightZone,
    RussianRegion,
    RussianRegionWithWater,
)

logger = logging.getLogger(__name__)


class FlightDataParser:
    """–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –ø–∞—Ä—Å–µ—Ä –¥–∞–Ω–Ω—ã—Ö –æ –ø–æ–ª–µ—Ç–∞—Ö."""

    def __init__(self):
        self.errors = []
        self.processed_count = 0
        self.created_count = 0
        self.duplicates_count = 0
        self.skipped_count = 0
        self.duplicates_count = 0
        self.actual_flights_count = 0

        self.validation_stats = {
            "total_rows": 0,
            "valid_shr": 0,
            "valid_dep": 0,
            "valid_arr": 0,
            "complete_flights": 0,
            "incomplete_flights": 0,
            "parsing_errors": 0,
            "only_shr": 0,
            "partial_dep_arr": 0,
            "flights_with_actual": 0,
        }

        self._operator_cache = {}
        self._drone_type_cache = {}
        self._flight_zone_cache = {}
        self._region_timezone_cache = {}
        self._flight_plans_batch = []
        self._actual_flights_batch = []
        self._batch_size = 5000
        self._processing_batch_size = 500

        self._regex_cache = self._compile_regex_patterns()

        self.utc_tz = pytz.UTC

    def _compile_regex_patterns(self) -> dict[str, re.Pattern]:
        """–ü—Ä–µ–¥–∫–æ–º–ø–∏–ª—è—Ü–∏—è –≤—Å–µ—Ö —Ä–µ–≥—É–ª—è—Ä–Ω—ã—Ö –≤—ã—Ä–∞–∂–µ–Ω–∏–π."""
        patterns = {
            "flight_id": re.compile(r"SHR-([A-Z0-9]+)"),
            "sid": re.compile(r"SID/(\d+)"),
            "zzzz_times": re.compile(r"-ZZZZ(\d{4})"),
            "altitude": re.compile(r"-M(\d{4})/M(\d{4})"),
            "dep_coord": re.compile(r"DEP/(\d{4}N\d{5}E)"),
            "dest_coord": re.compile(r"DEST/(\d{4}N\d{5}E)"),
            "zona_coord": re.compile(r"(\d{4}N\d{5}E)"),
            "date": re.compile(r"DOF/(\d{6})"),
            "operator": re.compile(r"OPR/(.+?)(?:REG/|TYP/|RMK/|SID/|$)", re.DOTALL),
            "drone_type": re.compile(r"TYP/([A-Z]+)"),
            "reg_number": re.compile(r"REG/([^,\s]+)"),
            "zona_matches": [
                re.compile(r"/ZONA\s+([A-Z0-9,.\s]+?)/"),
                re.compile(r"ZONA\s+([A-Z0-9,.\s]+)"),
                re.compile(r"WR(\d+)"),
            ],
            "purpose": re.compile(r"RMK/(.+?)(?:SID/|$)", re.DOTALL),
            "phone": re.compile(r"\+?7?\d{10,11}"),
            "coord_standard": re.compile(r"(\d{2})(\d{2})([NS])(\d{3})(\d{2})([EW])"),
            "coord_extended": re.compile(
                r"(\d{2})(\d{2})(\d{2})([NS])(\d{3})(\d{2})(\d{2})([EW])"
            ),
            # DEP/ARR –ø–∞—Ç—Ç–µ—Ä–Ω—ã
            "dep_date": re.compile(r"-ADD\s+(\d{6})"),
            "dep_time": re.compile(r"-ATD\s+(\d{4})"),
            "dep_coord_ext": re.compile(r"-ADEPZ\s+(\d{6}N\d{7}E)"),
            "arr_date": re.compile(r"-ADA\s+(\d{6})"),
            "arr_time": re.compile(r"-ATA\s+(\d{4})"),
            "arr_coord_ext": re.compile(r"-ADARRZ\s+(\d{6}N\d{7}E)"),
        }
        return patterns

    async def parse_excel_file_optimized(self, excel_file) -> dict[str, Any]:
        """
        –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ Excel —Ñ–∞–π–ª–∞.
        """
        self.errors = []
        self.processed_count = 0
        self.created_count = 0
        self.duplicates_count = 0

        self._operator_cache.clear()
        self._drone_type_cache.clear()
        self._flight_zone_cache.clear()
        self._flight_plans_batch.clear()
        self._actual_flights_batch.clear()

        self.skipped_count = 0
        self.actual_flights_count = 0
        self.validation_stats = {
            "total_rows": 0,
            "valid_shr": 0,
            "valid_dep": 0,
            "valid_arr": 0,
            "complete_flights": 0,
            "incomplete_flights": 0,
            "parsing_errors": 0,
            "only_shr": 0,
            "partial_dep_arr": 0,
            "invalid_dep_arr": 0,
        }

        try:

            logger.info("üöÄ –ù–∞—á–∏–Ω–∞—é —Å—Ç—Ä–∏–º–∏–Ω–≥–æ–≤—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É –±–æ–ª—å—à–æ–≥–æ Excel —Ñ–∞–π–ª–∞")

            total_rows = 0

            logger.info("üìè –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞—é –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫...")
            df_temp = pd.read_excel(
                excel_file,
                sheet_name=0,
                usecols=["SHR"],
                dtype=str,
                engine="openpyxl",
            )
            total_rows = len(df_temp.dropna(subset=["SHR"]))
            del df_temp

            logger.info(f"üìä –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ {total_rows} —Å—Ç—Ä–æ–∫ –¥–∞–Ω–Ω—ã—Ö")

            if total_rows > 50000:
                logger.info("‚ö†Ô∏è  –ë–û–õ–¨–®–û–ô –§–ê–ô–õ: –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω —Ä–µ–∂–∏–º —Å—Ç—Ä–∏–º–∏–Ω–≥–æ–≤–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏")
                result = await self._process_large_file_streaming(
                    excel_file, total_rows
                )
            else:
                logger.info("üìÇ –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞")
                result = await self._process_standard_file(excel_file)

            return result

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–º –ø–∞—Ä—Å–∏–Ω–≥–µ: {e}")
            await self._enable_db_constraints()
            raise ValidationError(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞: {str(e)}")

    async def _disable_db_constraints(self):
        """–ê–≥—Ä–µ—Å—Å–∏–≤–Ω–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ë–î –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π —Å–∫–æ—Ä–æ—Å—Ç–∏."""
        from asgiref.sync import sync_to_async

        @sync_to_async
        def disable_constraints():
            with connection.cursor() as cursor:

                cursor.execute("SET autocommit = false;")

                cursor.execute("SET work_mem = '1GB';")
                cursor.execute("SET maintenance_work_mem = '1GB';")

                cursor.execute("SET synchronous_commit = off;")
                cursor.execute("SET fsync = off;")
                cursor.execute("SET checkpoint_segments = 32;")
                cursor.execute("SET wal_buffers = '16MB';")
                cursor.execute("SET shared_buffers = '512MB';")

                cursor.execute("SET full_page_writes = off;")

        try:
            await disable_constraints()
            logger.info("‚ö° –ë–î –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–∞ –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π —Å–∫–æ—Ä–æ—Å—Ç–∏ –∑–∞–≥—Ä—É–∑–∫–∏!")
        except Exception as e:
            logger.warning(f"–ß–∞—Å—Ç–∏—á–Ω–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ë–î: {e}")

    async def _enable_db_constraints(self):
        """–ü–æ–ª–Ω–æ–µ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –±–µ–∑–æ–ø–∞—Å–Ω—ã—Ö –Ω–∞—Å—Ç—Ä–æ–µ–∫ –ë–î."""
        from asgiref.sync import sync_to_async

        @sync_to_async
        def enable_constraints():
            with connection.cursor() as cursor:
                cursor.execute("SET autocommit = true;")
                cursor.execute("SET work_mem = '4MB';")
                cursor.execute("SET maintenance_work_mem = '64MB';")
                cursor.execute("SET synchronous_commit = on;")
                cursor.execute("SET fsync = on;")
                cursor.execute("SET full_page_writes = on;")
                cursor.execute("SET shared_buffers = '128MB';")

        try:
            await enable_constraints()
            logger.info("üîí –ë–î –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã –≤ –±–µ–∑–æ–ø–∞—Å–Ω—ã–π —Ä–µ–∂–∏–º")
        except Exception as e:
            logger.warning(f"–ß–∞—Å—Ç–∏—á–Ω–æ–µ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –ë–î: {e}")

    async def _preload_caches_async(self):
        """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –∫–µ—à–µ–π."""
        from asgiref.sync import sync_to_async

        @sync_to_async
        def load_caches():

            operators = list(DroneOperator.objects.all().values("id", "name"))
            for op in operators:
                self._operator_cache[op["name"].lower()[:100]] = op["id"]

            drone_types = list(DroneType.objects.all().values("id", "code"))
            for dt in drone_types:
                self._drone_type_cache[dt["code"]] = dt["id"]

            flight_zones = list(FlightZone.objects.all().values("id", "code"))
            for fz in flight_zones:
                self._flight_zone_cache[fz["code"]] = fz["id"]

            regions = list(
                RussianRegion.objects.exclude(timezone="").values("code", "timezone")
            )
            for region in regions:
                try:
                    timezone_obj = pytz.timezone(region["timezone"])
                    self._region_timezone_cache[region["code"]] = timezone_obj
                except pytz.exceptions.UnknownTimeZoneError:
                    logger.warning(
                        f"–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π —á–∞—Å–æ–≤–æ–π –ø–æ—è—Å {region['timezone']} –¥–ª—è —Ä–µ–≥–∏–æ–Ω–∞ {region['code']}"
                    )
                    self._region_timezone_cache[region["code"]] = pytz.timezone(
                        "Europe/Moscow"
                    )

        await load_caches()
        logger.info(
            f"–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–µ –∫–µ—à–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã: –æ–ø–µ—Ä–∞—Ç–æ—Ä—ã={len(self._operator_cache)}, "
            f"—Ç–∏–ø—ã={len(self._drone_type_cache)}, –∑–æ–Ω—ã={len(self._flight_zone_cache)}, "
            f"—á–∞—Å–æ–≤—ã–µ –ø–æ—è—Å–∞ —Ä–µ–≥–∏–æ–Ω–æ–≤={len(self._region_timezone_cache)}"
        )

    async def _process_dataframe_super_async(self, df: pd.DataFrame) -> dict[str, Any]:
        """–°—É–ø–µ—Ä-–∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–º –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º–æ–º."""

        chunk_size = 1000
        chunks = [df.iloc[i : i + chunk_size] for i in range(0, len(df), chunk_size)]

        logger.info(
            f"üîÑ –ó–∞–ø—É—Å–∫–∞—é –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É {len(chunks)} –±–ª–æ–∫–æ–≤ –¥–∞–Ω–Ω—ã—Ö..."
        )

        with ProcessPoolExecutor(max_workers=12) as process_executor:
            parse_futures = []
            for chunk_idx, chunk in enumerate(chunks):
                future = process_executor.submit(
                    self._process_chunk_in_process, chunk, chunk_idx, self._regex_cache
                )
                parse_futures.append(future)

            parsed_batches = []
            completed_chunks = 0
            total_chunks = len(parse_futures)

            for future in as_completed(parse_futures):
                try:
                    batch_result = future.result()
                    if batch_result["data"]:
                        parsed_batches.extend(batch_result["data"])
                    self.processed_count += batch_result["processed"]
                    self.errors.extend(batch_result["errors"])

                    completed_chunks += 1
                    progress = (completed_chunks / total_chunks) * 100
                    logger.info(
                        f"üìä –ü—Ä–æ–≥—Ä–µ—Å—Å –ø–∞—Ä—Å–∏–Ω–≥–∞: {completed_chunks}/{total_chunks} –±–ª–æ–∫–æ–≤ ({progress:.1f}%)"
                    )

                except Exception as e:
                    logger.error(f"–û—à–∏–±–∫–∞ –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ –ø–∞—Ä—Å–∏–Ω–≥–∞: {e}")
                    completed_chunks += 1

        if parsed_batches:
            logger.info(
                f"üíæ –ù–∞—á–∏–Ω–∞—é —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ {len(parsed_batches)} –∑–∞–ø–∏—Å–µ–π –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö..."
            )
            await self._super_bulk_save(parsed_batches)
            logger.info("‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ!")

        return {
            "processed": self.processed_count,
            "created": self.created_count,
            "actual_flights_created": self.actual_flights_count,
            "skipped": self.skipped_count,
            "duplicates": self.duplicates_count,
            "errors": len(self.errors),
            "error_messages": self.errors,
            "validation_stats": self.validation_stats,
        }

    @staticmethod
    def _process_chunk_in_process(
        chunk: pd.DataFrame, chunk_idx: int, regex_cache: dict
    ) -> dict[str, Any]:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ —á–∞–Ω–∫–∞ –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø—Ä–æ—Ü–µ—Å—Å–µ (—Å—Ç–∞—Ç–∏—á–µ—Å–∫–∏–π –º–µ—Ç–æ–¥)."""
        errors = []
        processed = 0
        parsed_data = []

        for index, row in chunk.iterrows():
            try:
                shr_data = str(row.get("SHR", ""))
                dep_data = str(row.get("DEP", ""))
                arr_data = str(row.get("ARR", ""))

                has_shr = shr_data and shr_data != "nan" and shr_data.strip()
                has_dep = dep_data and dep_data != "nan" and dep_data.strip()
                has_arr = arr_data and arr_data != "nan" and arr_data.strip()

                if not has_shr:
                    errors.append(f"–°—Ç—Ä–æ–∫–∞ {index + 2}: –û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç SHR –¥–∞–Ω–Ω—ã–µ")
                    continue

                if not has_dep:
                    errors.append(f"–°—Ç—Ä–æ–∫–∞ {index + 2}: –û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç DEP –¥–∞–Ω–Ω—ã–µ")
                    continue

                if not has_arr:
                    errors.append(f"–°—Ç—Ä–æ–∫–∞ {index + 2}: –û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç ARR –¥–∞–Ω–Ω—ã–µ")
                    continue

                if not FlightDataParser._validate_shr_template(shr_data):
                    errors.append(
                        f"–°—Ç—Ä–æ–∫–∞ {index + 2}: SHR –¥–∞–Ω–Ω—ã–µ –Ω–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç —à–∞–±–ª–æ–Ω—É (–¥–æ–ª–∂–Ω—ã –Ω–∞—á–∏–Ω–∞—Ç—å—Å—è —Å SHR)"
                    )
                    continue

                if not FlightDataParser._validate_dep_template(dep_data):
                    errors.append(
                        f"–°—Ç—Ä–æ–∫–∞ {index + 2}: DEP –¥–∞–Ω–Ω—ã–µ –Ω–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç —à–∞–±–ª–æ–Ω—É (–¥–æ–ª–∂–Ω—ã –Ω–∞—á–∏–Ω–∞—Ç—å—Å—è —Å -TITLE)"
                    )
                    continue

                if not FlightDataParser._validate_arr_template(arr_data):
                    errors.append(
                        f"–°—Ç—Ä–æ–∫–∞ {index + 2}: ARR –¥–∞–Ω–Ω—ã–µ –Ω–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç —à–∞–±–ª–æ–Ω—É (–¥–æ–ª–∂–Ω—ã –Ω–∞—á–∏–Ω–∞—Ç—å—Å—è —Å -TITLE)"
                    )
                    continue

                flight_data = FlightDataParser._parse_shr_fast(shr_data, regex_cache)
                if not flight_data:
                    errors.append(f"–°—Ç—Ä–æ–∫–∞ {index + 2}: –ù–µ —É–¥–∞–ª–æ—Å—å –ø–∞—Ä—Å–∏—Ç—å SHR –¥–∞–Ω–Ω—ã–µ")
                    continue

                actual_data = FlightDataParser._parse_dep_arr_fast(
                    dep_data, arr_data, regex_cache
                )

                parsed_data.append(
                    {
                        "flight_data": flight_data,
                        "actual_data": actual_data,
                        "row_index": index,
                    }
                )
                processed += 1

            except Exception as e:
                error_msg = f"–°—Ç—Ä–æ–∫–∞ {index + 2}: {str(e)}"
                errors.append(error_msg)
                logger.error(
                    f"–î–ï–¢–ê–õ–¨–ù–ê–Ø –û–®–ò–ë–ö–ê –±—ã—Å—Ç—Ä–æ–≥–æ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å—Ç—Ä–æ–∫–∏ {index + 2}: {e}"
                )
                logger.error(
                    f"SHR –¥–∞–Ω–Ω—ã–µ: {shr_data[:100] if 'shr_data' in locals() else 'N/A'}..."
                )
                logger.error(
                    f"DEP –¥–∞–Ω–Ω—ã–µ: {dep_data[:100] if 'dep_data' in locals() else 'N/A'}..."
                )
                logger.error(
                    f"ARR –¥–∞–Ω–Ω—ã–µ: {arr_data[:100] if 'arr_data' in locals() else 'N/A'}..."
                )

        logger.info(
            f"‚öôÔ∏è  –ü—Ä–æ—Ü–µ—Å—Å {chunk_idx}: –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ {processed} —Å—Ç—Ä–æ–∫, –æ—à–∏–±–æ–∫: {len(errors)}"
        )
        return {"data": parsed_data, "processed": processed, "errors": errors}

    @staticmethod
    def _validate_shr_template(shr_text: str) -> bool:
        """–í–∞–ª–∏–¥–∞—Ü–∏—è —à–∞–±–ª–æ–Ω–∞ SHR –¥–∞–Ω–Ω—ã—Ö."""
        if not shr_text or shr_text == "nan":
            return False

        cleaned_text = shr_text.strip()

        return cleaned_text.startswith("SHR")

    @staticmethod
    def _validate_dep_template(dep_text: str) -> bool:
        """–í–∞–ª–∏–¥–∞—Ü–∏—è —à–∞–±–ª–æ–Ω–∞ DEP –¥–∞–Ω–Ω—ã—Ö."""
        if not dep_text or dep_text == "nan":
            return False

        cleaned_text = dep_text.strip()

        return cleaned_text.startswith("-TITLE")

    @staticmethod
    def _validate_arr_template(arr_text: str) -> bool:
        """–í–∞–ª–∏–¥–∞—Ü–∏—è —à–∞–±–ª–æ–Ω–∞ ARR –¥–∞–Ω–Ω—ã—Ö."""
        if not arr_text or arr_text == "nan":
            return False

        cleaned_text = arr_text.strip()

        return cleaned_text.startswith("-TITLE")

    @staticmethod
    def _parse_shr_fast(shr_text: str, regex_cache: dict) -> dict[str, Any] | None:
        """–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –±—ã—Å—Ç—Ä—ã–π –ø–∞—Ä—Å–∏–Ω–≥ SHR —Å –ø—Ä–µ–¥–∫–æ–º–ø–∏–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ regex."""
        if not shr_text:
            return None

        cleaned_text = (
            shr_text.strip().replace("(", "").replace(")", "").replace('"', "")
        )
        data = {}

        try:

            match = regex_cache["flight_id"].search(cleaned_text)
            if match:
                flight_id = match.group(1)
                data["flight_id"] = (
                    flight_id[:47] + "..." if len(flight_id) > 50 else flight_id
                )

            match = regex_cache["sid"].search(cleaned_text)
            if match:
                sid = match.group(1)
                data["sid"] = sid[:17] + "..." if len(sid) > 20 else sid

            times = regex_cache["zzzz_times"].findall(cleaned_text)
            if len(times) >= 1:
                data["departure_time"] = times[0]
            if len(times) >= 2:
                data["duration"] = FlightDataParser._calc_duration_fast(
                    times[0], times[1]
                )

            match = regex_cache["altitude"].search(cleaned_text)
            if match:
                data["min_alt"] = int(match.group(1))
                data["max_alt"] = int(match.group(2))

            match = regex_cache["dep_coord"].search(cleaned_text)
            if match:
                data["dep_coords"] = match.group(1)

            match = regex_cache["dest_coord"].search(cleaned_text)
            if match:
                data["dest_coords"] = match.group(1)
            elif not data.get("dest_coords"):
                match = regex_cache["zona_coord"].search(cleaned_text)
                if match:
                    data["dep_coords"] = data.get("dep_coords", match.group(1))
                    data["dest_coords"] = match.group(1)

            match = regex_cache["date"].search(cleaned_text)
            if match:
                data["date"] = match.group(1)

            match = regex_cache["operator"].search(cleaned_text)
            if match:
                data["operator"] = match.group(1).strip()[:1000]

            match = regex_cache["drone_type"].search(cleaned_text)
            if match:
                data["drone_type"] = match.group(1)

            match = regex_cache["reg_number"].search(cleaned_text)
            if match:
                reg = match.group(1).strip()
                data["reg_number"] = reg[:47] + "..." if len(reg) > 50 else reg

            match = regex_cache["purpose"].search(cleaned_text)
            if match:
                data["purpose"] = match.group(1).strip()

            return data

        except Exception:
            return None

    @staticmethod
    def _parse_dep_arr_fast(
        dep_text: str, arr_text: str, regex_cache: dict
    ) -> dict[str, Any] | None:
        """–ë—ã—Å—Ç—Ä—ã–π –ø–∞—Ä—Å–∏–Ω–≥ DEP/ARR."""
        data = {}

        try:
            if dep_text and dep_text != "nan":
                dep_clean = dep_text.strip().replace('"', "")

                match = regex_cache["dep_date"].search(dep_clean)
                if match:
                    data["dep_date"] = match.group(1)

                match = regex_cache["dep_time"].search(dep_clean)
                if match:
                    data["dep_time"] = match.group(1)

                match = regex_cache["dep_coord_ext"].search(dep_clean)
                if match:
                    data["dep_coords_ext"] = match.group(1)

            if arr_text and arr_text != "nan":
                arr_clean = arr_text.strip().replace('"', "")

                match = regex_cache["arr_date"].search(arr_clean)
                if match:
                    data["arr_date"] = match.group(1)

                match = regex_cache["arr_time"].search(arr_clean)
                if match:
                    data["arr_time"] = match.group(1)

                match = regex_cache["arr_coord_ext"].search(arr_clean)
                if match:
                    data["arr_coords_ext"] = match.group(1)

            result = {
                "raw_data": {
                    "dep": dep_text if dep_text and dep_text != "nan" else "",
                    "arr": arr_text if arr_text and arr_text != "nan" else "",
                }
            }
            result.update(data)
            return result

        except Exception:
            return {
                "raw_data": {
                    "dep": dep_text if dep_text and dep_text != "nan" else "",
                    "arr": arr_text if arr_text and arr_text != "nan" else "",
                }
            }

    @staticmethod
    def _validate_actual_flight_data(actual_data: dict[str, Any]) -> bool:
        """
        –ì–∏–±–∫–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö –ø–æ–ª–µ—Ç–∞.
        –¢—Ä–µ–±—É–µ—Ç –Ω–∞–ª–∏—á–∏—è —Ö–æ—Ç—è –±—ã –æ–¥–Ω–æ–≥–æ —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞.
        """
        if not actual_data:
            return False

        has_any_dep = (
            actual_data.get("actual_departure_date")
            or actual_data.get("actual_departure_time")
            or actual_data.get("actual_departure_point")
            or actual_data.get("dep_date")
            or actual_data.get("dep_time")
        )

        has_any_arr = (
            actual_data.get("actual_arrival_date")
            or actual_data.get("actual_arrival_time")
            or actual_data.get("actual_destination_point")
            or actual_data.get("arr_date")
            or actual_data.get("arr_time")
        )

        return has_any_dep or has_any_arr

    def _get_regional_timezone(
        self, departure_region_code: str = None, destination_region_code: str = None
    ) -> pytz.BaseTzInfo:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ —á–∞—Å–æ–≤–æ–≥–æ –ø–æ—è—Å–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–≥–∏–æ–Ω–æ–≤ –ø–æ–ª–µ—Ç–∞ –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö.

        Args:
            departure_region_code: –ö–æ–¥ —Ä–µ–≥–∏–æ–Ω–∞ –≤—ã–ª–µ—Ç–∞
            destination_region_code: –ö–æ–¥ —Ä–µ–≥–∏–æ–Ω–∞ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è

        Returns:
            –ß–∞—Å–æ–≤–æ–π –ø–æ—è—Å —Ä–µ–≥–∏–æ–Ω–∞ –∏–ª–∏ –º–æ—Å–∫–æ–≤—Å–∫–æ–µ –≤—Ä–µ–º—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        """

        region_code = departure_region_code or destination_region_code

        if region_code:

            if region_code in self._region_timezone_cache:
                return self._region_timezone_cache[region_code]

            try:

                region = RussianRegion.objects.filter(code=region_code).first()
                timezone_obj = None

                if region and region.timezone:
                    try:
                        timezone_obj = pytz.timezone(region.timezone)

                        self._region_timezone_cache[region_code] = timezone_obj
                        return timezone_obj
                    except pytz.exceptions.UnknownTimeZoneError:
                        logger.warning(
                            f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —á–∞—Å–æ–≤–æ–π –ø–æ—è—Å –∏–∑ –ë–î: {region.timezone} –¥–ª—è —Ä–µ–≥–∏–æ–Ω–∞ {region_code}"
                        )
                elif region:
                    logger.debug(
                        f"–£ —Ä–µ–≥–∏–æ–Ω–∞ {region_code} ({region.name}) –Ω–µ —É–∫–∞–∑–∞–Ω —á–∞—Å–æ–≤–æ–π –ø–æ—è—Å"
                    )
                else:
                    logger.debug(f"–†–µ–≥–∏–æ–Ω —Å –∫–æ–¥–æ–º {region_code} –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –ë–î")

            except Exception as e:
                logger.error(
                    f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —á–∞—Å–æ–≤–æ–≥–æ –ø–æ—è—Å–∞ –¥–ª—è —Ä–µ–≥–∏–æ–Ω–∞ {region_code}: {e}"
                )

            moscow_tz = pytz.timezone("Europe/Moscow")
            self._region_timezone_cache[region_code] = moscow_tz
            return moscow_tz

        return pytz.timezone("Europe/Moscow")

    def _convert_utc_to_regional(
        self, utc_datetime: datetime, region_code: str = None
    ) -> datetime:
        """
        –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤—Ä–µ–º–µ–Ω–∏ –∏–∑ UTC –≤ —Ä–µ–≥–∏–æ–Ω–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è.

        Args:
            utc_datetime: Datetime –≤ UTC
            region_code: –ö–æ–¥ —Ä–µ–≥–∏–æ–Ω–∞ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —á–∞—Å–æ–≤–æ–≥–æ –ø–æ—è—Å–∞

        Returns:
            Datetime –≤ —Ä–µ–≥–∏–æ–Ω–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏
        """
        if not utc_datetime:
            return utc_datetime

        try:

            if utc_datetime.tzinfo is not None:
                utc_dt = utc_datetime.astimezone(self.utc_tz)
            else:

                utc_dt = self.utc_tz.localize(utc_datetime)

            regional_tz = self._get_regional_timezone(region_code)

            regional_dt = utc_dt.astimezone(regional_tz)

            logger.debug(
                f"–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤—Ä–µ–º–µ–Ω–∏: {utc_datetime} UTC -> {regional_dt.replace(tzinfo=None)} {regional_tz} (—Ä–µ–≥–∏–æ–Ω: {region_code})"
            )

            return regional_dt.replace(tzinfo=None)

        except Exception as e:
            logger.error(
                f"–û—à–∏–±–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ –≤—Ä–µ–º–µ–Ω–∏ UTC->Regional –¥–ª—è —Ä–µ–≥–∏–æ–Ω–∞ {region_code}: {e}"
            )
            logger.debug(f"UTC datetime: {utc_datetime}, region_code: {region_code}")
            return utc_datetime

    def _parse_time_with_timezone_conversion(
        self, time_str: str, date_obj: datetime.date = None, region_code: str = None
    ) -> time:
        """
        –ü–∞—Ä—Å–∏–Ω–≥ –≤—Ä–µ–º–µ–Ω–∏ —Å –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–µ–π –∏–∑ UTC –≤ —Ä–µ–≥–∏–æ–Ω–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è.

        Args:
            time_str: –°—Ç—Ä–æ–∫–∞ –≤—Ä–µ–º–µ–Ω–∏ –≤ —Ñ–æ—Ä–º–∞—Ç–µ HHMM
            date_obj: –î–∞—Ç–∞ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –ø–æ–ª–Ω–æ–≥–æ datetime
            region_code: –ö–æ–¥ —Ä–µ–≥–∏–æ–Ω–∞ –¥–ª—è —á–∞—Å–æ–≤–æ–≥–æ –ø–æ—è—Å–∞

        Returns:
            time –æ–±—ä–µ–∫—Ç –≤ —Ä–µ–≥–∏–æ–Ω–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏
        """
        if not time_str or len(time_str) != 4:
            return time(0, 0)

        try:
            hours = int(time_str[:2])
            minutes = int(time_str[2:])

            if not (0 <= hours <= 23 and 0 <= minutes <= 59):
                return time(0, 0)

            if date_obj and region_code:
                utc_datetime = datetime.combine(date_obj, time(hours, minutes))
                regional_datetime = self._convert_utc_to_regional(
                    utc_datetime, region_code
                )
                return regional_datetime.time()
            else:

                return time(hours, minutes)

        except ValueError:
            return time(0, 0)

    def _calculate_actual_flight_duration(self, dep_date, dep_time, arr_date, arr_time):
        """
        –†–∞—Å—á–µ—Ç —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–æ–π –ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –ø–æ–ª–µ—Ç–∞.

        Args:
            dep_date: –î–∞—Ç–∞ –≤—ã–ª–µ—Ç–∞ (datetime.date)
            dep_time: –í—Ä–µ–º—è –≤—ã–ª–µ—Ç–∞ (datetime.time)
            arr_date: –î–∞—Ç–∞ –ø—Ä–∏–ª–µ—Ç–∞ (datetime.date)
            arr_time: –í—Ä–µ–º—è –ø—Ä–∏–ª–µ—Ç–∞ (datetime.time)

        Returns:
            timedelta –∏–ª–∏ None
        """
        try:

            departure_datetime = datetime.combine(dep_date, dep_time)
            arrival_datetime = datetime.combine(arr_date, arr_time)

            duration = arrival_datetime - departure_datetime

            if timedelta(minutes=1) <= duration <= timedelta(hours=24):
                return duration
            else:
                logger.warning(f"–ù–µ—Ä–∞–∑—É–º–Ω–∞—è –ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –ø–æ–ª–µ—Ç–∞: {duration}")
                return None

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Ä–∞—Å—á–µ—Ç–∞ –ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –ø–æ–ª–µ—Ç–∞: {e}")
            return None

    @staticmethod
    def _calc_duration_fast(start: str, end: str) -> int:
        """–ë—ã—Å—Ç—Ä—ã–π —Ä–∞—Å—á–µ—Ç –ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –≤ –º–∏–Ω—É—Ç–∞—Ö."""
        try:
            start_mins = int(start[:2]) * 60 + int(start[2:])
            end_mins = int(end[:2]) * 60 + int(end[2:])

            if end_mins < start_mins:
                end_mins += 24 * 60

            return max(60, min(24 * 60, end_mins - start_mins))
        except:
            return 60

    async def _super_bulk_save(self, parsed_batches: list[dict[str, Any]]):
        """–°—É–ø–µ—Ä-–±—ã—Å—Ç—Ä–æ–µ –º–∞—Å—Å–æ–≤–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ."""
        logger.info(f"–ù–∞—á–∏–Ω–∞—é —Å—É–ø–µ—Ä-bulk —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ {len(parsed_batches)} –∑–∞–ø–∏—Å–µ–π")

        super_batch_size = 10000
        total_created = 0

        for i in range(0, len(parsed_batches), super_batch_size):
            batch = parsed_batches[i : i + super_batch_size]

            try:
                result = await self._save_super_batch(batch)
                if isinstance(result, dict):
                    created_count = result["created"]
                    duplicates_count = result["duplicates"]
                    total_created += created_count
                    self.duplicates_count += duplicates_count
                else:

                    created_count = result
                    total_created += created_count
                logger.info(
                    f"–°—É–ø–µ—Ä-–±–∞—Ç—á —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {created_count} –∑–∞–ø–∏—Å–µ–π, –ø—Ä–æ–ø—É—â–µ–Ω–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {duplicates_count if isinstance(result, dict) else 0}"
                )

            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ —Å—É–ø–µ—Ä-–±–∞—Ç—á–∞: {e}")

                for j in range(0, len(batch), 100):
                    small_batch = batch[j : j + 100]
                    try:
                        result = await self._save_super_batch(small_batch)
                        if isinstance(result, dict):
                            created = result["created"]
                            duplicates_count = result["duplicates"]
                            total_created += created
                            self.duplicates_count += duplicates_count
                        else:

                            created = result
                            total_created += created
                    except Exception as e2:
                        logger.error(f"–û—à–∏–±–∫–∞ –º–∞–ª–æ–≥–æ –±–∞—Ç—á–∞: {e2}")

        self.created_count = total_created
        logger.info(f"–°—É–ø–µ—Ä-bulk –∑–∞–≤–µ—Ä—à–µ–Ω: {total_created} –∑–∞–ø–∏—Å–µ–π")

    async def _save_super_batch(self, batch: list[dict[str, Any]]) -> int:
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å—É–ø–µ—Ä-–±–∞—Ç—á–∞ —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π."""
        from asgiref.sync import sync_to_async

        @sync_to_async
        def save_batch_optimized():
            from django.db import connection

            with connection.cursor() as cursor:

                flight_plans_data = []

                for item in batch:
                    flight_data = item["flight_data"]

                    operator_id = self._get_operator_id_fast(
                        flight_data.get("operator", "")
                    )
                    drone_type_id = self._get_drone_type_id_fast(
                        flight_data.get("drone_type", "BLA")
                    )

                    flight_plan_data = {
                        "flight_id": flight_data.get(
                            "flight_id", f"UK_{len(flight_plans_data)}"
                        ),
                        "sid": flight_data.get("sid", ""),
                        "reg_number": flight_data.get("reg_number", ""),
                        "operator_id": operator_id,
                        "drone_type_id": drone_type_id,
                    }
                    flight_plans_data.append(flight_plan_data)

                flight_plans = []
                for data in flight_plans_data:
                    fp = FlightPlan(**data)
                    flight_plans.append(fp)

                filtered_flight_plans = []
                sids_to_check = [fp.sid for fp in flight_plans if fp.sid]
                duplicates_found = 0

                if sids_to_check:

                    existing_sids = set(
                        FlightPlan.objects.filter(sid__in=sids_to_check).values_list(
                            "sid", flat=True
                        )
                    )

                    for fp in flight_plans:
                        if not fp.sid or fp.sid not in existing_sids:
                            filtered_flight_plans.append(fp)
                        else:
                            duplicates_found += 1
                            logger.debug(
                                f"–ü—Ä–æ–ø—É—Å–∫–∞–µ–º –¥—É–±–ª–∏—Ä—É—é—â–∏–π –ø–ª–∞–Ω –ø–æ–ª–µ—Ç–∞ —Å SID: {fp.sid}"
                            )
                else:
                    filtered_flight_plans = flight_plans

                created = FlightPlan.objects.bulk_create(
                    filtered_flight_plans, batch_size=10000, ignore_conflicts=True
                )

                return {"created": len(created), "duplicates": duplicates_found}

        return await save_batch_optimized()

    def _get_operator_id_fast(self, operator_info: str) -> str:
        """–ë—ã—Å—Ç—Ä–æ–µ –ø–æ–ª—É—á–µ–Ω–∏–µ ID –æ–ø–µ—Ä–∞—Ç–æ—Ä–∞ –∏–∑ –∫–µ—à–∞."""
        if not operator_info:
            return self._drone_type_cache.get("DEFAULT_OPERATOR")

        normalized = operator_info.lower()[:100]
        return self._operator_cache.get(
            normalized, self._create_operator_fast(operator_info)
        )

    def _get_drone_type_id_fast(self, code: str) -> str:
        """–ë—ã—Å—Ç—Ä–æ–µ –ø–æ–ª—É—á–µ–Ω–∏–µ ID —Ç–∏–ø–∞ –ë–ê–°."""
        return self._drone_type_cache.get(code, self._drone_type_cache.get("BLA"))

    def _create_operator_fast(self, operator_info: str) -> str:
        """–ë—ã—Å—Ç—Ä–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ –æ–ø–µ—Ä–∞—Ç–æ—Ä–∞."""
        try:
            operator = DroneOperator.objects.create(
                name=operator_info[:500], organization_type="–ü—Ä–æ—á–∏–µ"
            )
            return operator.id
        except:
            return self._drone_type_cache.get("DEFAULT_OPERATOR")

    async def _process_large_file_streaming(
        self, excel_file, total_rows: int
    ) -> dict[str, Any]:
        """–°—Ç—Ä–∏–º–∏–Ω–≥–æ–≤–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ—á–µ–Ω—å –±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–æ–≤ (76k+ –∑–∞–ø–∏—Å–µ–π)."""

        logger.info("‚ö° –ê–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω —Ä–µ–∂–∏–º —Å—Ç—Ä–∏–º–∏–Ω–≥–æ–≤–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–ª—è –±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–æ–≤")

        await self._disable_db_constraints()
        await self._preload_caches_async()

        chunk_size = 1000
        processed_total = 0

        try:

            for chunk_start in range(0, total_rows, chunk_size):
                chunk_end = min(chunk_start + chunk_size, total_rows)
                logger.info(
                    f"üì¶ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é —á–∞–Ω–∫ {chunk_start // chunk_size + 1}/{(total_rows + chunk_size - 1) // chunk_size}: —Å—Ç—Ä–æ–∫–∏ {chunk_start}-{chunk_end}"
                )

                df_chunk = pd.read_excel(
                    excel_file,
                    sheet_name=0,
                    usecols=["SHR", "DEP", "ARR"],
                    dtype=str,
                    engine="openpyxl",
                    skiprows=range(1, chunk_start + 1),
                    nrows=chunk_end - chunk_start,
                )

                df_chunk = df_chunk.dropna(subset=["SHR"])
                df_chunk = df_chunk[df_chunk["SHR"] != "nan"]

                if len(df_chunk) == 0:
                    continue

                await self._process_dataframe_super_async(df_chunk)
                processed_total += len(df_chunk)

                del df_chunk

                progress = (processed_total / total_rows) * 100
                logger.info(
                    f"üéØ –û–±—â–∏–π –ø—Ä–æ–≥—Ä–µ—Å—Å: {processed_total}/{total_rows} ({progress:.1f}%)"
                )

                await asyncio.sleep(0.1)

        finally:
            await self._enable_db_constraints()

        return {
            "processed": self.processed_count,
            "created": self.created_count,
            "actual_flights_created": self.actual_flights_count,
            "skipped": self.skipped_count,
            "duplicates": self.duplicates_count,
            "errors": len(self.errors),
            "error_messages": self.errors,
            "validation_stats": self.validation_stats,
        }

    async def _process_standard_file(self, excel_file) -> dict[str, Any]:
        """–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è —Ñ–∞–π–ª–æ–≤ < 50k –∑–∞–ø–∏—Å–µ–π."""

        df = pd.read_excel(
            excel_file,
            sheet_name=0,
            usecols=["SHR", "DEP", "ARR"],
            dtype=str,
            engine="openpyxl",
        )

        df = df.dropna(subset=["SHR"])
        df = df[df["SHR"] != "nan"]

        logger.info(
            f"‚öôÔ∏è  –ù–∞—Å—Ç—Ä–æ–π–∫–∏: –±–∞—Ç—á–∏ –ø–æ {self._batch_size}, –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ {self._processing_batch_size} —Å—Ç—Ä–æ–∫"
        )

        await self._disable_db_constraints()

        await self._preload_caches_async()

        result = await self._process_dataframe_super_async(df)

        await self._enable_db_constraints()

        return result

    parse_excel_file = parse_excel_file_optimized

    def parse_excel_file(self, excel_file) -> dict[str, Any]:
        """
        –°–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ Excel —Ñ–∞–π–ª–∞ —Å –¥–∞–Ω–Ω—ã–º–∏ –æ –ø–æ–ª–µ—Ç–∞—Ö.

        Args:
            excel_file: –ó–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π Excel —Ñ–∞–π–ª

        Returns:
            Dict —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –ø–∞—Ä—Å–∏–Ω–≥–∞
        """
        self.errors = []
        self.processed_count = 0
        self.created_count = 0
        self.duplicates_count = 0

        self._operator_cache.clear()
        self._drone_type_cache.clear()
        self._flight_zone_cache.clear()
        self._flight_plans_batch.clear()
        self._actual_flights_batch.clear()

        self.skipped_count = 0
        self.actual_flights_count = 0
        self.validation_stats = {
            "total_rows": 0,
            "valid_shr": 0,
            "valid_dep": 0,
            "valid_arr": 0,
            "complete_flights": 0,
            "incomplete_flights": 0,
            "parsing_errors": 0,
            "only_shr": 0,
            "partial_dep_arr": 0,
            "invalid_dep_arr": 0,
        }

        try:

            df = pd.read_excel(excel_file, sheet_name=0)
            logger.info(f"–ù–∞—á–∏–Ω–∞—é –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É {len(df)} —Å—Ç—Ä–æ–∫")

            self._preload_caches()

            return asyncio.run(self._process_dataframe_async(df))

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ Excel —Ñ–∞–π–ª–∞: {e}")
            raise ValidationError(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞: {str(e)}")

    def _preload_caches(self):
        """–ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –∫–µ—à–µ–π –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –¥–æ—Å—Ç—É–ø–∞."""

        for operator in DroneOperator.objects.all():
            self._operator_cache[operator.name.lower()[:100]] = operator

        for drone_type in DroneType.objects.all():
            self._drone_type_cache[drone_type.code] = drone_type

        for flight_zone in FlightZone.objects.all():
            self._flight_zone_cache[flight_zone.code] = flight_zone

        logger.info(
            f"–ö–µ—à–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã: –æ–ø–µ—Ä–∞—Ç–æ—Ä—ã={len(self._operator_cache)}, "
            f"—Ç–∏–ø—ã –ë–ê–°={len(self._drone_type_cache)}, "
            f"–∑–æ–Ω—ã={len(self._flight_zone_cache)}"
        )

    async def _process_dataframe_async(self, df: pd.DataFrame) -> dict[str, Any]:
        """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ DataFrame —Å –±–∞—Ç—á–∞–º–∏."""

        batch_size = 500
        batches = [df.iloc[i : i + batch_size] for i in range(0, len(df), batch_size)]

        with ThreadPoolExecutor(max_workers=16) as executor:
            futures = [
                executor.submit(self._process_batch_sync, batch, batch_idx)
                for batch_idx, batch in enumerate(batches)
            ]

            for future in as_completed(futures):
                try:
                    batch_results = future.result()
                    self.processed_count += batch_results["processed"]
                    self.errors.extend(batch_results["errors"])
                except Exception as e:
                    logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –±–∞—Ç—á–∞: {e}")
                    self.errors.append(f"–û—à–∏–±–∫–∞ –±–∞—Ç—á–∞: {str(e)}")

        await self._bulk_save_data()

        return {
            "processed": self.processed_count,
            "created": self.created_count,
            "actual_flights_created": self.actual_flights_count,
            "skipped": self.skipped_count,
            "duplicates": self.duplicates_count,
            "errors": len(self.errors),
            "error_messages": self.errors,
            "validation_stats": self.validation_stats,
        }

    def _process_batch_sync(
        self, batch: pd.DataFrame, batch_idx: int
    ) -> dict[str, Any]:
        """–°–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ –±–∞—Ç—á–∞ —Å—Ç—Ä–æ–∫."""
        batch_errors = []
        processed = 0

        for index, row in batch.iterrows():
            try:

                shr_data = str(row.get("SHR", ""))
                dep_data = str(row.get("DEP", ""))
                arr_data = str(row.get("ARR", ""))

                if not shr_data or shr_data == "nan":
                    batch_errors.append(f"–°—Ç—Ä–æ–∫–∞ {index + 2}: –û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç SHR –¥–∞–Ω–Ω—ã–µ")
                    continue

                has_dep = dep_data and dep_data != "nan" and dep_data.strip()
                has_arr = arr_data and arr_data != "nan" and arr_data.strip()

                if not has_dep:
                    batch_errors.append(f"–°—Ç—Ä–æ–∫–∞ {index + 2}: –û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç DEP –¥–∞–Ω–Ω—ã–µ")
                    continue

                if not has_arr:
                    batch_errors.append(f"–°—Ç—Ä–æ–∫–∞ {index + 2}: –û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç ARR –¥–∞–Ω–Ω—ã–µ")
                    continue

                flight_plan_data = self._parse_shr_data(shr_data)
                if not flight_plan_data:
                    batch_errors.append(
                        f"–°—Ç—Ä–æ–∫–∞ {index + 2}: –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –¥–∞–Ω–Ω—ã–µ –ø–ª–∞–Ω–∞ –ø–æ–ª–µ—Ç–∞ –∏–∑ SHR"
                    )
                    continue

                actual_flight_data = self._parse_dep_arr_data(
                    dep_data, arr_data, flight_plan_data
                )

                self._add_to_batch(flight_plan_data, actual_flight_data, index)
                processed += 1

            except Exception as e:
                error_msg = f"–°—Ç—Ä–æ–∫–∞ {index + 2}: {str(e)}"
                batch_errors.append(error_msg)
                logger.error(f"–î–ï–¢–ê–õ–¨–ù–ê–Ø –û–®–ò–ë–ö–ê –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å—Ç—Ä–æ–∫–∏ {index + 2}: {e}")
                logger.error(
                    f"SHR –¥–∞–Ω–Ω—ã–µ: {shr_data[:100] if 'shr_data' in locals() else 'N/A'}..."
                )
                logger.error(
                    f"DEP –¥–∞–Ω–Ω—ã–µ: {dep_data[:100] if 'dep_data' in locals() else 'N/A'}..."
                )
                logger.error(
                    f"ARR –¥–∞–Ω–Ω—ã–µ: {arr_data[:100] if 'arr_data' in locals() else 'N/A'}..."
                )

        logger.info(
            f"–ë–∞—Ç—á {batch_idx} –æ–±—Ä–∞–±–æ—Ç–∞–Ω: {processed} —Å—Ç—Ä–æ–∫, {len(batch_errors)} –æ—à–∏–±–æ–∫"
        )
        return {"processed": processed, "errors": batch_errors}

    def _add_to_batch(
        self,
        flight_plan_data: dict[str, Any],
        actual_flight_data: dict[str, Any],
        row_index: int,
    ):
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –≤ –±–∞—Ç—á–∏ –¥–ª—è bulk –æ–ø–µ—Ä–∞—Ü–∏–π."""

        operator = self._get_or_create_operator_cached(
            flight_plan_data.get("operator_info", "")
        )
        drone_type = self._get_or_create_drone_type_cached(
            flight_plan_data.get("drone_type_code", "BLA")
        )
        flight_zone = None
        if flight_plan_data.get("flight_zone_code"):
            flight_zone = self._get_or_create_flight_zone_cached(
                flight_plan_data["flight_zone_code"]
            )

        departure_region = None
        destination_region = None

        departure_point = flight_plan_data.get("departure_point", Point(0, 0))
        destination_point = flight_plan_data.get("destination_point", Point(0, 0))

        if departure_point and departure_point.x != 0 and departure_point.y != 0:
            departure_region = self._assign_region_by_coordinates(departure_point)

        if destination_point and destination_point.x != 0 and destination_point.y != 0:
            destination_region = self._assign_region_by_coordinates(destination_point)

        departure_region_code = departure_region.code if departure_region else None
        destination_region_code = (
            destination_region.code if destination_region else None
        )

        planned_departure_time_utc = flight_plan_data.get("planned_departure_time")
        if isinstance(planned_departure_time_utc, time) and flight_plan_data.get(
            "planned_date"
        ):

            utc_dt = datetime.combine(
                flight_plan_data["planned_date"], planned_departure_time_utc
            )
            regional_dt = self._convert_utc_to_regional(utc_dt, departure_region_code)
            planned_departure_time = regional_dt.time()
        else:
            planned_departure_time = planned_departure_time_utc or time(0, 0)

        flight_plan_obj = FlightPlan(
            flight_id=flight_plan_data.get(
                "flight_id",
                f"UNKNOWN_{timezone.now().strftime('%Y%m%d%H%M%S')}_{row_index}",
            ),
            sid=flight_plan_data.get("sid", ""),
            reg_number=flight_plan_data.get("reg_number", ""),
            planned_date=flight_plan_data.get("planned_date", timezone.now().date()),
            planned_departure_time=planned_departure_time,
            planned_duration=flight_plan_data.get(
                "planned_duration", timedelta(hours=1)
            ),
            min_altitude=flight_plan_data.get("min_altitude", 0),
            max_altitude=flight_plan_data.get("max_altitude", 100),
            departure_point=departure_point,
            destination_point=destination_point,
            departure_region=departure_region,
            destination_region=destination_region,
            operator=operator,
            drone_type=drone_type,
            flight_zone=flight_zone,
            purpose=flight_plan_data.get("purpose", ""),
            raw_data=flight_plan_data.get("raw_data", {}),
        )

        self._flight_plans_batch.append(
            {
                "flight_plan": flight_plan_obj,
                "actual_flight_data": actual_flight_data,
                "row_index": row_index,
                "temp_id": f"{row_index}_{flight_plan_obj.flight_id}",
            }
        )

    async def _bulk_save_data(self):
        """–ú–∞—Å—Å–æ–≤–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –≤ –±–∞–∑—É."""
        if not self._flight_plans_batch:
            return

        logger.info(
            f"–ù–∞—á–∏–Ω–∞—é bulk —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ {len(self._flight_plans_batch)} –ø–ª–∞–Ω–æ–≤ –ø–æ–ª–µ—Ç–æ–≤"
        )

        batch_size = self._batch_size
        total_created = 0

        for i in range(0, len(self._flight_plans_batch), batch_size):
            batch = self._flight_plans_batch[i : i + batch_size]

            try:

                batch_result = await self._save_batch_sync(batch, batch_size)
                if isinstance(batch_result, dict):
                    created_count = batch_result["created"]
                    duplicates_count = batch_result["duplicates"]
                    total_created += created_count
                    self.duplicates_count += duplicates_count
                else:

                    total_created += batch_result

            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ bulk —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –±–∞—Ç—á–∞: {e}")

                await self._fallback_single_save(batch)

        self.created_count = total_created
        logger.info(
            f"Bulk —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ: —Å–æ–∑–¥–∞–Ω–æ {total_created} –ø–ª–∞–Ω–æ–≤ –ø–æ–ª–µ—Ç–æ–≤"
        )

    async def _save_batch_sync(
        self, batch: list[dict[str, Any]], batch_size: int
    ) -> int:
        """–°–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –±–∞—Ç—á–∞ –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ."""
        from asgiref.sync import sync_to_async

        @sync_to_async
        def save_batch():
            with transaction.atomic():

                flight_plans = [item["flight_plan"] for item in batch]

                filtered_flight_plans = []
                sids_to_check = [fp.sid for fp in flight_plans if fp.sid]
                duplicates_found = 0

                if sids_to_check:

                    existing_sids = set(
                        FlightPlan.objects.filter(sid__in=sids_to_check).values_list(
                            "sid", flat=True
                        )
                    )

                    for fp in flight_plans:
                        if not fp.sid or fp.sid not in existing_sids:
                            filtered_flight_plans.append(fp)
                        else:
                            duplicates_found += 1
                            logger.debug(
                                f"–ü—Ä–æ–ø—É—Å–∫–∞–µ–º –¥—É–±–ª–∏—Ä—É—é—â–∏–π –ø–ª–∞–Ω –ø–æ–ª–µ—Ç–∞ —Å SID: {fp.sid}"
                            )
                else:
                    filtered_flight_plans = flight_plans

                created_flight_plans = FlightPlan.objects.bulk_create(
                    filtered_flight_plans, ignore_conflicts=True, batch_size=10000
                )

                created_count = len(created_flight_plans)

                if created_flight_plans:
                    actual_flights = []

                    actual_data_map = {}
                    for item in batch:
                        if item["actual_flight_data"]:
                            actual_data_map[item["flight_plan"].id] = item[
                                "actual_flight_data"
                            ]

                    for plan in created_flight_plans:
                        actual_data = actual_data_map.get(plan.id)
                        if actual_data:

                            dep_region_code = (
                                plan.departure_region.code
                                if plan.departure_region
                                else None
                            )
                            dest_region_code = (
                                plan.destination_region.code
                                if plan.destination_region
                                else None
                            )

                            actual_departure_time = actual_data.get(
                                "actual_departure_time"
                            )
                            actual_departure_date = actual_data.get(
                                "actual_departure_date"
                            )
                            if (
                                actual_departure_time
                                and actual_data.get("dep_time_utc_raw")
                                and actual_departure_date
                            ):
                                utc_dt = datetime.combine(
                                    actual_departure_date, actual_departure_time
                                )
                                regional_dt = self._convert_utc_to_regional(
                                    utc_dt, dep_region_code
                                )
                                actual_departure_time = regional_dt.time()
                                actual_departure_date = regional_dt.date()

                            actual_arrival_time = actual_data.get("actual_arrival_time")
                            actual_arrival_date = actual_data.get("actual_arrival_date")
                            if (
                                actual_arrival_time
                                and actual_data.get("arr_time_utc_raw")
                                and actual_arrival_date
                            ):
                                utc_dt = datetime.combine(
                                    actual_arrival_date, actual_arrival_time
                                )
                                regional_dt = self._convert_utc_to_regional(
                                    utc_dt, dest_region_code or dep_region_code
                                )
                                actual_arrival_time = regional_dt.time()
                                actual_arrival_date = regional_dt.date()

                            actual_duration = None
                            if (
                                actual_departure_date
                                and actual_departure_time
                                and actual_arrival_date
                                and actual_arrival_time
                            ):
                                actual_duration = (
                                    self._calculate_actual_flight_duration(
                                        actual_departure_date,
                                        actual_departure_time,
                                        actual_arrival_date,
                                        actual_arrival_time,
                                    )
                                )

                            actual_flight = ActualFlight(
                                flight_plan=plan,
                                actual_departure_date=actual_departure_date,
                                actual_departure_time=actual_departure_time,
                                actual_departure_point=actual_data.get(
                                    "actual_departure_point"
                                ),
                                actual_arrival_date=actual_arrival_date,
                                actual_arrival_time=actual_arrival_time,
                                actual_destination_point=actual_data.get(
                                    "actual_destination_point"
                                ),
                                actual_duration=actual_duration,
                                flight_status="completed",
                            )
                            actual_flights.append(actual_flight)

                    if actual_flights:
                        created_actual = ActualFlight.objects.bulk_create(
                            actual_flights, ignore_conflicts=True, batch_size=10000
                        )

                        self.actual_flights_count += len(created_actual)

                return {"created": created_count, "duplicates": duplicates_found}

        return await save_batch()

    async def _fallback_single_save(self, batch: list[dict[str, Any]]):
        """–†–µ–∑–µ—Ä–≤–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø–æ –æ–¥–Ω–æ–º—É –æ–±—ä–µ–∫—Ç—É –ø—Ä–∏ –æ—à–∏–±–∫–µ bulk –æ–ø–µ—Ä–∞—Ü–∏–∏."""
        from asgiref.sync import sync_to_async

        @sync_to_async
        def save_single_item(item):
            try:
                with transaction.atomic():
                    flight_plan = item["flight_plan"]
                    flight_plan.save()

                    if item["actual_flight_data"]:
                        actual_flight = ActualFlight(
                            flight_plan=flight_plan,
                            **{
                                k: v
                                for k, v in item["actual_flight_data"].items()
                                if k.startswith("actual_")
                            },
                        )
                        actual_flight.save()

                    return 1
            except Exception as e:
                logger.error(
                    f"–û—à–∏–±–∫–∞ fallback —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Å—Ç—Ä–æ–∫–∏ {item['row_index'] + 2}: {e}"
                )
                return 0

        saved_count = 0
        for item in batch:
            result = await save_single_item(item)
            saved_count += result

        self.created_count += saved_count

    def _assign_region_by_coordinates(self, point: Point) -> Optional["RussianRegion"]:
        """
        –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–µ–≥–∏–æ–Ω–∞ –ø–æ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞–º —Ç–æ—á–∫–∏.

        Args:
            point: –ì–µ–æ–ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω–∞—è —Ç–æ—á–∫–∞

        Returns:
            –†–µ–≥–∏–æ–Ω –∏–ª–∏ None –µ—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω
        """
        try:

            region = RussianRegion.objects.filter(geometry__contains=point).first()

            if region:
                logger.debug(f"–¢–æ—á–∫–∞ {point} –Ω–∞–π–¥–µ–Ω–∞ –≤ –æ—Å–Ω–æ–≤–Ω–æ–º —Ä–µ–≥–∏–æ–Ω–µ {region.name}")
                return region

            water_region = RussianRegionWithWater.objects.filter(
                geometry__contains=point
            ).first()

            if water_region:

                corresponding_region = RussianRegion.objects.filter(
                    code=water_region.code
                ).first()

                if corresponding_region:
                    logger.debug(
                        f"–¢–æ—á–∫–∞ {point} –Ω–∞–π–¥–µ–Ω–∞ –≤ –≤–æ–¥–Ω–æ–π –≥—Ä–∞–Ω–∏—Ü–µ —Ä–µ–≥–∏–æ–Ω–∞ {water_region.name}, "
                        f"–Ω–∞–∑–Ω–∞—á–µ–Ω —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π –æ—Å–Ω–æ–≤–Ω–æ–π —Ä–µ–≥–∏–æ–Ω {corresponding_region.name}"
                    )
                    return corresponding_region
                else:
                    logger.warning(
                        f"–ù–∞–π–¥–µ–Ω –≤–æ–¥–Ω—ã–π —Ä–µ–≥–∏–æ–Ω {water_region.name} ({water_region.code}), "
                        f"–Ω–æ –Ω–µ –Ω–∞–π–¥–µ–Ω —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π –æ—Å–Ω–æ–≤–Ω–æ–π —Ä–µ–≥–∏–æ–Ω"
                    )

            logger.debug(
                f"–†–µ–≥–∏–æ–Ω –¥–ª—è —Ç–æ—á–∫–∏ {point} –Ω–µ –Ω–∞–π–¥–µ–Ω –Ω–∏ –≤ –æ—Å–Ω–æ–≤–Ω—ã—Ö, –Ω–∏ –≤ –≤–æ–¥–Ω—ã—Ö –≥—Ä–∞–Ω–∏—Ü–∞—Ö"
            )
            return None

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–∏ —Ä–µ–≥–∏–æ–Ω–∞ –¥–ª—è —Ç–æ—á–∫–∏ {point}: {e}")
            return None

    def _get_or_create_operator_cached(self, operator_info: str) -> DroneOperator:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏–ª–∏ —Å–æ–∑–¥–∞–Ω–∏–µ –æ–ø–µ—Ä–∞—Ç–æ—Ä–∞ –ë–ê–° —Å –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º."""
        if not operator_info:
            operator_info = "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –æ–ø–µ—Ä–∞—Ç–æ—Ä"

        normalized_name = self._normalize_operator_name(operator_info)
        cache_key = normalized_name.lower()[:100]

        if cache_key in self._operator_cache:
            return self._operator_cache[cache_key]

        operator = self._create_operator_from_info(operator_info, normalized_name)
        self._operator_cache[cache_key] = operator
        return operator

    def _normalize_operator_name(self, operator_info: str) -> str:
        """–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∏–º–µ–Ω–∏ –æ–ø–µ—Ä–∞—Ç–æ—Ä–∞."""
        operator_info = operator_info[:1000]

        phone_pattern = r"\+?7?\d{10,11}"
        phones = re.findall(phone_pattern, operator_info)

        name = operator_info
        for phone in phones:
            name = name.replace(phone, "")

        cleanup_words = ["–û–ü–ï–†–ê–¢–û–†", "–ê–î–ú–ò–ù–ò–°–¢–†–ê–¶–ò–Ø", "–†–ê–ó–†–ï–®–ï–ù–ò–ï", "–¢–ï–õ", "TEL"]
        for word in cleanup_words:
            name = re.sub(r"\b" + word + r"\b", "", name, flags=re.IGNORECASE)

        name = re.sub(r"\s+", " ", name).strip()
        name = re.sub(r"^[.,\-\s]+", "", name)
        name = re.sub(r"[.,\-\s]+$", "", name)

        if not name or len(name) < 3:
            org_pattern = (
                r"^([–ê-–Ø–Å\s]+(?:–ú–í–î|–ú–ß–°|–ê–î–ú–ò–ù–ò–°–¢–†–ê–¶–ò–Ø|–£–ü–†–ê–í–õ–ï–ù–ò–ï|–°–õ–£–ñ–ë–ê)[–ê-–Ø–Å\s]*)"
            )
            org_match = re.search(org_pattern, operator_info, re.IGNORECASE)
            name = org_match.group(1).strip() if org_match else "–û–ø–µ—Ä–∞—Ç–æ—Ä –ë–ê–°"

        return name[:500]

    def _create_operator_from_info(
        self, operator_info: str, name: str
    ) -> DroneOperator:
        """–°–æ–∑–¥–∞–Ω–∏–µ –æ–ø–µ—Ä–∞—Ç–æ—Ä–∞ –∏–∑ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏."""

        phone_pattern = r"\+?7?\d{10,11}"
        phones = re.findall(phone_pattern, operator_info)
        primary_phone = phones[0] if phones else ""

        if any(word in operator_info.upper() for word in ["–ú–í–î", "–ü–û–õ–ò–¶"]):
            organization_type = "–ú–í–î"
        elif any(word in operator_info.upper() for word in ["–ú–ß–°", "–°–ü–ê–°–ê–¢–ï–õ–¨–ù"]):
            organization_type = "–ú–ß–°"
        elif any(
            word in operator_info.upper() for word in ["–ê–î–ú–ò–ù–ò–°–¢–†–ê–¶–ò–Ø", "–ú–£–ù–ò–¶–ò–ü–ê–õ–¨–ù"]
        ):
            organization_type = "–ê–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ü–∏—è"
        elif any(
            word in operator_info.upper() for word in ["–£–ü–†–ê–í–õ–ï–ù–ò–ï", "–î–ï–ü–ê–†–¢–ê–ú–ï–ù–¢"]
        ):
            organization_type = "–ì–æ—Å—É–¥–∞—Ä—Å—Ç–≤–µ–Ω–Ω—ã–π –æ—Ä–≥–∞–Ω"
        elif any(word in operator_info.upper() for word in ["–°–õ–£–ñ–ë–ê"]):
            organization_type = "–°–ª—É–∂–±–∞"
        else:
            organization_type = "–ü—Ä–æ—á–∏–µ"

        operator, created = DroneOperator.objects.get_or_create(
            name=name,
            defaults={
                "phone": primary_phone[:20],
                "organization_type": organization_type[:200],
            },
        )

        return operator

    def _get_or_create_drone_type_cached(self, code: str) -> DroneType:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏–ª–∏ —Å–æ–∑–¥–∞–Ω–∏–µ —Ç–∏–ø–∞ –ë–ê–° —Å –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º."""
        if not code:
            code = "BLA"

        if code in self._drone_type_cache:
            return self._drone_type_cache[code]

        type_names = {
            "BLA": "–ë–µ—Å–ø–∏–ª–æ—Ç–Ω–∞—è –∞–≤–∏–∞—Ü–∏–æ–Ω–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞",
            "AER": "–ê—ç—Ä–æ—Å—Ç–∞—Ç",
            "UAV": "–ë–µ—Å–ø–∏–ª–æ—Ç–Ω—ã–π –ª–µ—Ç–∞—Ç–µ–ª—å–Ω—ã–π –∞–ø–ø–∞—Ä–∞—Ç",
        }

        drone_type, created = DroneType.objects.get_or_create(
            code=code,
            defaults={
                "name": type_names.get(code, f"–ë–ê–° —Ç–∏–ø–∞ {code}"),
                "description": f"–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–æ–∑–¥–∞–Ω–Ω—ã–π —Ç–∏–ø {code}",
            },
        )

        self._drone_type_cache[code] = drone_type
        return drone_type

    def _get_or_create_flight_zone_cached(self, code: str) -> FlightZone:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏–ª–∏ —Å–æ–∑–¥–∞–Ω–∏–µ –∑–æ–Ω—ã –ø–æ–ª–µ—Ç–∞ —Å –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º."""
        if not code:
            code = "UNKNOWN"

        original_code = code
        code = code[:50]
        if len(original_code) > 50:
            code = original_code[:20] + "..." + original_code[-20:]
            if len(code) > 50:
                code = original_code[:47] + "..."
        code = re.sub(r"\s+", " ", code).strip()

        if code in self._flight_zone_cache:
            return self._flight_zone_cache[code]

        flight_zone, created = FlightZone.objects.get_or_create(
            code=code, defaults={"name": f"–ó–æ–Ω–∞ {code}"}
        )

        self._flight_zone_cache[code] = flight_zone
        return flight_zone

    def _parse_shr_data(self, shr_text: str) -> dict[str, Any] | None:
        """–ü–∞—Ä—Å–∏–Ω–≥ –¥–∞–Ω–Ω—ã—Ö –∏–∑ —Å—Ç–æ–ª–±—Ü–∞ SHR (–ø–ª–∞–Ω –ø–æ–ª–µ—Ç–∞)."""
        if not shr_text:
            return None

        cleaned_text = (
            shr_text.strip().replace("(", "").replace(")", "").replace('"', "")
        )
        data = {"raw_data": {"shr": cleaned_text}}

        try:

            flight_id_match = re.search(r"SHR-([A-Z0-9]+)", cleaned_text)
            if flight_id_match:
                flight_id_value = flight_id_match.group(1)
                if flight_id_value == "ZZZZZ":
                    data["flight_id"] = "ZZZZZ"
                    reg_match = re.search(r"REG/([^,\s]+)", cleaned_text)
                    if reg_match:
                        reg_number = reg_match.group(1).strip()

                        if len(reg_number) > 50:
                            reg_number = reg_number[:47] + "..."
                        data["reg_number"] = reg_number
                    else:
                        data["reg_number"] = ""
                else:

                    if len(flight_id_value) > 50:
                        flight_id_value = flight_id_value[:47] + "..."
                    data["flight_id"] = flight_id_value
                    reg_match = re.search(r"REG/([^,\s]+)", cleaned_text)
                    if reg_match:
                        reg_number = reg_match.group(1).strip()
                        if len(reg_number) > 50:
                            reg_number = reg_number[:47] + "..."
                        data["reg_number"] = reg_number

            sid_match = re.search(r"SID/(\d+)", cleaned_text)
            if sid_match:
                sid_value = sid_match.group(1)

                if len(sid_value) > 20:
                    sid_value = sid_value[:17] + "..."
                data["sid"] = sid_value

            time_matches = re.findall(r"-ZZZZ(\d{4})", cleaned_text)
            if len(time_matches) >= 1:

                data["planned_departure_time_utc_raw"] = time_matches[0]
                data["planned_departure_time"] = self._parse_time(time_matches[0])
            if len(time_matches) >= 2:
                data["planned_duration"] = self._parse_duration(
                    time_matches[0], time_matches[1]
                )
            else:
                data["planned_duration"] = timedelta(hours=1)

            altitude_match = re.search(r"-M(\d{4})/M(\d{4})", cleaned_text)
            if altitude_match:
                data["min_altitude"] = int(altitude_match.group(1))
                data["max_altitude"] = int(altitude_match.group(2))

            dep_coord_match = re.search(r"DEP/(\d{4}N\d{5}E)", cleaned_text)
            if dep_coord_match:
                data["departure_point"] = self._parse_coordinates(
                    dep_coord_match.group(1)
                )

            dest_coord_match = re.search(r"DEST/(\d{4}N\d{5}E)", cleaned_text)
            if dest_coord_match:
                data["destination_point"] = self._parse_coordinates(
                    dest_coord_match.group(1)
                )

            if "destination_point" not in data:
                zona_coord_match = re.search(r"(\d{4}N\d{5}E)", cleaned_text)
                if zona_coord_match:
                    coord_str = zona_coord_match.group(1)
                    if "departure_point" not in data:
                        data["departure_point"] = self._parse_coordinates(coord_str)
                    data["destination_point"] = self._parse_coordinates(coord_str)

            date_match = re.search(r"DOF/(\d{6})", cleaned_text)
            if date_match:
                data["planned_date"] = self._parse_date(date_match.group(1))

            opr_match = re.search(
                r"OPR/(.+?)(?:REG/|TYP/|RMK/|SID/|$)", cleaned_text, re.DOTALL
            )
            if opr_match:
                data["operator_info"] = re.sub(r"\s+", " ", opr_match.group(1).strip())

            typ_match = re.search(r"TYP/([A-Z]+)", cleaned_text)
            if typ_match:
                data["drone_type_code"] = typ_match.group(1)

            zona_matches = [
                re.search(r"/ZONA\s+([A-Z0-9,.\s]+?)/", cleaned_text),
                re.search(r"ZONA\s+([A-Z0-9,.\s]+)", cleaned_text),
                re.search(r"WR(\d+)", cleaned_text),
            ]
            for zona_match in zona_matches:
                if zona_match:
                    zone_code = zona_match.group(1).strip()
                    if zone_code:
                        data["flight_zone_code"] = zone_code
                        break

            rmk_match = re.search(r"RMK/(.+?)(?:SID/|$)", cleaned_text, re.DOTALL)
            if rmk_match:
                data["purpose"] = re.sub(r"\s+", " ", rmk_match.group(1).strip())

            return data

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ SHR –¥–∞–Ω–Ω—ã—Ö: {e}")
            return None

    def _parse_dep_arr_data(
        self,
        dep_text: str,
        arr_text: str,
        flight_plan_data: dict[str, Any] | None = None,
    ) -> dict[str, Any] | None:
        """–ü–∞—Ä—Å–∏–Ω–≥ –¥–∞–Ω–Ω—ã—Ö DEP –∏ ARR."""
        data = {"raw_data": {"dep": dep_text, "arr": arr_text}}

        try:
            if dep_text and dep_text != "nan" and dep_text.strip():
                dep_clean = dep_text.strip().replace('"', "")

                dep_date_match = re.search(r"-ADD\s+(\d{6})", dep_clean)
                if dep_date_match:
                    dep_date = self._parse_date(dep_date_match.group(1))
                    data["actual_departure_date"] = dep_date
                    data["dep_date"] = dep_date_match.group(1)

                dep_time_match = re.search(r"-ATD\s+(\d{4})", dep_clean)
                if dep_time_match:
                    dep_time = self._parse_time(dep_time_match.group(1))
                    data["actual_departure_time"] = dep_time
                    data["dep_time"] = dep_time_match.group(1)
                    data["dep_time_utc_raw"] = dep_time_match.group(1)

            if arr_text and arr_text != "nan" and arr_text.strip():
                arr_clean = arr_text.strip().replace('"', "")

                arr_date_match = re.search(r"-ADA\s+(\d{6})", arr_clean)
                if arr_date_match:
                    arr_date = self._parse_date(arr_date_match.group(1))
                    data["actual_arrival_date"] = arr_date
                    data["arr_date"] = arr_date_match.group(1)

                arr_time_match = re.search(r"-ATA\s+(\d{4})", arr_clean)
                if arr_time_match:
                    arr_time = self._parse_time(arr_time_match.group(1))
                    data["actual_arrival_time"] = arr_time
                    data["arr_time"] = arr_time_match.group(1)
                    data["arr_time_utc_raw"] = arr_time_match.group(1)

            if flight_plan_data:
                if "departure_point" in flight_plan_data:
                    data["actual_departure_point"] = flight_plan_data["departure_point"]

                if "destination_point" in flight_plan_data:
                    data["actual_destination_point"] = flight_plan_data[
                        "destination_point"
                    ]

            return data

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ DEP/ARR –¥–∞–Ω–Ω—ã—Ö: {e}")
            return {"raw_data": {"dep": dep_text, "arr": arr_text}}

    def _parse_coordinates(self, coord_str: str) -> Point:
        """–ü–∞—Ä—Å–∏–Ω–≥ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç DDMMNDDDMME -> –¥–µ—Å—è—Ç–∏—á–Ω—ã–µ –≥—Ä–∞–¥—É—Å—ã."""
        if not coord_str:
            return Point(0, 0)

        pattern = r"(\d{2})(\d{2})([NS])(\d{3})(\d{2})([EW])"
        match = re.match(pattern, coord_str)
        if not match:
            logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã: {coord_str}")
            return Point(0, 0)

        lat_deg, lat_min, lat_dir, lon_deg, lon_min, lon_dir = match.groups()
        try:
            latitude = float(lat_deg) + float(lat_min) / 60
            longitude = float(lon_deg) + float(lon_min) / 60

            if lat_dir == "S":
                latitude = -latitude
            if lon_dir == "W":
                longitude = -longitude

            return Point(longitude, latitude)
        except ValueError as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç {coord_str}: {e}")
            return Point(0, 0)

    def _parse_coordinates_extended(self, coord_str: str) -> Point:
        """–ü–∞—Ä—Å–∏–Ω–≥ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç DDMMSSNDDDMMSSE -> –¥–µ—Å—è—Ç–∏—á–Ω—ã–µ –≥—Ä–∞–¥—É—Å—ã."""
        if not coord_str:
            return Point(0, 0)

        logger.info(f"–ü–∞—Ä—Å–∏–Ω–≥ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç: '{coord_str}'")

        patterns = [
            r"(\d{2})(\d{2})([NS])(\d{3})(\d{2})([EW])",
            r"(\d{2})(\d{2})(\d{2})([NS])(\d{3})(\d{2})(\d{2})([EW])",
        ]

        for i, pattern in enumerate(patterns):
            match = re.match(pattern, coord_str)
            if match:
                groups = match.groups()
                logger.info(f"–ö–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç –ø–∞—Ç—Ç–µ—Ä–Ω—É {i}: {groups}")

                try:
                    if len(groups) == 6:
                        lat_deg, lat_min, lat_dir, lon_deg, lon_min, lon_dir = groups
                        latitude = float(lat_deg) + float(lat_min) / 60
                        longitude = float(lon_deg) + float(lon_min) / 60
                        logger.info(
                            f"–ü–∞—Ä—Å–∏–º –±–µ–∑ —Å–µ–∫—É–Ω–¥: lat={lat_deg}¬∞{lat_min}'{lat_dir} = {latitude}, lon={lon_deg}¬∞{lon_min}'{lon_dir} = {longitude}"
                        )
                    elif len(groups) == 8:
                        (
                            lat_deg,
                            lat_min,
                            lat_sec,
                            lat_dir,
                            lon_deg,
                            lon_min,
                            lon_sec,
                            lon_dir,
                        ) = groups
                        latitude = (
                            float(lat_deg) + float(lat_min) / 60 + float(lat_sec) / 3600
                        )
                        longitude = (
                            float(lon_deg) + float(lon_min) / 60 + float(lon_sec) / 3600
                        )
                        logger.info(
                            f"–ü–∞—Ä—Å–∏–º —Å —Å–µ–∫—É–Ω–¥–∞–º–∏: lat={lat_deg}¬∞{lat_min}'{lat_sec}\"{lat_dir} = {latitude}, lon={lon_deg}¬∞{lon_min}'{lon_sec}\"{lon_dir} = {longitude}"
                        )
                    else:
                        continue

                    if lat_dir == "S":
                        latitude = -latitude
                    if lon_dir == "W":
                        longitude = -longitude

                    point = Point(longitude, latitude)
                    logger.info(f"–ö–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã —É—Å–ø–µ—à–Ω–æ —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω—ã: {point}")
                    return point

                except (ValueError, TypeError) as e:
                    logger.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç {coord_str}: {e}")
                    continue

        logger.warning(f"–ò—Å–ø–æ–ª—å–∑—É–µ–º fallback –¥–ª—è –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç: '{coord_str}'")
        return self._parse_coordinates(coord_str)

    def _parse_time(self, time_str: str) -> time:
        """–ü–∞—Ä—Å–∏–Ω–≥ –≤—Ä–µ–º–µ–Ω–∏ HHMM -> datetime.time."""
        if not time_str or len(time_str) != 4:
            return time(0, 0)

        try:
            hours = int(time_str[:2])
            minutes = int(time_str[2:])
            if 0 <= hours <= 23 and 0 <= minutes <= 59:
                return time(hours, minutes)
        except ValueError:
            pass

        return time(0, 0)

    def _parse_date(self, date_str: str) -> datetime.date:
        """–ü–∞—Ä—Å–∏–Ω–≥ –¥–∞—Ç—ã YYMMDD -> datetime.date."""
        if not date_str or len(date_str) != 6:
            return timezone.now().date()

        try:
            year = int("20" + date_str[:2])
            month = int(date_str[2:4])
            day = int(date_str[4:6])
            return datetime(year, month, day).date()
        except ValueError:
            return timezone.now().date()

    def _parse_duration(self, start_time_str: str, end_time_str: str) -> timedelta:
        """–ü–∞—Ä—Å–∏–Ω–≥ –ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∏–∑ –¥–≤—É—Ö –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –º–µ—Ç–æ–∫ HHMM -> timedelta."""
        try:
            start_hour = int(start_time_str[:2])
            start_minute = int(start_time_str[2:4])
            end_hour = int(end_time_str[:2])
            end_minute = int(end_time_str[2:4])

            start_minutes = start_hour * 60 + start_minute
            end_minutes = end_hour * 60 + end_minute

            if end_minutes < start_minutes:
                end_minutes += 24 * 60

            duration_minutes = end_minutes - start_minutes

            if duration_minutes <= 0:
                duration_minutes = 60
            elif duration_minutes > 24 * 60:
                duration_minutes = 24 * 60

            return timedelta(minutes=duration_minutes)
        except (ValueError, TypeError, IndexError):
            return timedelta(hours=1)

    def _process_row(self, index: int, row: pd.Series) -> None:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏ –¥–∞–Ω–Ω—ã—Ö —Å –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π DEP/ARR."""
        shr_data = str(row.get("SHR", ""))
        dep_data = str(row.get("DEP", ""))
        arr_data = str(row.get("ARR", ""))

        self.validation_stats["total_rows"] += 1

        has_shr = shr_data and shr_data != "nan" and shr_data.strip()
        has_dep = dep_data and dep_data != "nan" and dep_data.strip()
        has_arr = arr_data and arr_data != "nan" and arr_data.strip()

        if has_shr:
            self.validation_stats["valid_shr"] += 1
        if has_dep:
            self.validation_stats["valid_dep"] += 1
        if has_arr:
            self.validation_stats["valid_arr"] += 1

        if not has_shr:
            return
        if not has_dep:
            return
        if not has_arr:
            return

        flight_plan_data = self._parse_shr_data(shr_data)
        if not flight_plan_data:
            self.validation_stats["parsing_errors"] += 1
            raise ValueError("–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –¥–∞–Ω–Ω—ã–µ –ø–ª–∞–Ω–∞ –ø–æ–ª–µ—Ç–∞")

        actual_flight_data = self._parse_dep_arr_data(
            dep_data, arr_data, flight_plan_data
        )

        self.validation_stats["complete_flights"] += 1
        self.validation_stats["flights_with_actual"] += 1

        with transaction.atomic():
            flight_plan = self._create_flight_plan(flight_plan_data)

            if actual_flight_data:
                actual_flight = self._create_actual_flight_with_duration(
                    flight_plan, actual_flight_data
                )
                if actual_flight:
                    self.actual_flights_count += 1

            self.created_count += 1

    def _create_flight_plan(self, data: dict[str, Any]) -> FlightPlan:
        """–°–æ–∑–¥–∞–Ω–∏–µ –ø–ª–∞–Ω–∞ –ø–æ–ª–µ—Ç–∞ (—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)."""
        operator = self._get_or_create_operator(data.get("operator_info", ""))
        drone_type = self._get_or_create_drone_type(data.get("drone_type_code", "BLA"))
        flight_zone = None
        if data.get("flight_zone_code"):
            flight_zone = self._get_or_create_flight_zone(data["flight_zone_code"])

        departure_point = data.get("departure_point", Point(0, 0))
        destination_point = data.get("destination_point", Point(0, 0))

        departure_region = None
        destination_region = None

        if departure_point and departure_point.x != 0 and departure_point.y != 0:
            departure_region = self._assign_region_by_coordinates(departure_point)

        if destination_point and destination_point.x != 0 and destination_point.y != 0:
            destination_region = self._assign_region_by_coordinates(destination_point)

        departure_region_code = departure_region.code if departure_region else None

        sid = data.get("sid", "")
        if sid:
            existing_plan = FlightPlan.objects.filter(sid=sid).first()
            if existing_plan:
                logger.debug(f"–ü—Ä–æ–ø—É—Å–∫–∞–µ–º –¥—É–±–ª–∏—Ä—É—é—â–∏–π –ø–ª–∞–Ω –ø–æ–ª–µ—Ç–∞ —Å SID: {sid}")
                return existing_plan

        planned_departure_time_utc = data.get("planned_departure_time")
        if isinstance(planned_departure_time_utc, time) and data.get("planned_date"):

            utc_dt = datetime.combine(data["planned_date"], planned_departure_time_utc)
            regional_dt = self._convert_utc_to_regional(utc_dt, departure_region_code)
            planned_departure_time = regional_dt.time()
        else:
            planned_departure_time = planned_departure_time_utc or time(0, 0)

        return FlightPlan.objects.create(
            flight_id=data.get(
                "flight_id", f"UNKNOWN_{timezone.now().strftime('%Y%m%d%H%M%S')}"
            ),
            sid=data.get("sid", ""),
            reg_number=data.get("reg_number", ""),
            planned_date=data.get("planned_date", timezone.now().date()),
            planned_departure_time=planned_departure_time,
            planned_duration=data.get("planned_duration", timedelta(hours=1)),
            min_altitude=data.get("min_altitude", 0),
            max_altitude=data.get("max_altitude", 100),
            departure_point=departure_point,
            destination_point=destination_point,
            departure_region=departure_region,
            destination_region=destination_region,
            operator=operator,
            drone_type=drone_type,
            flight_zone=flight_zone,
            purpose=data.get("purpose", ""),
            raw_data=data.get("raw_data", {}),
        )

    def _create_actual_flight(
        self, flight_plan: FlightPlan, data: dict[str, Any]
    ) -> ActualFlight:
        """–°–æ–∑–¥–∞–Ω–∏–µ –∑–∞–ø–∏—Å–∏ —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–ª–µ—Ç–∞ —Å –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–µ–π –≤—Ä–µ–º–µ–Ω–∏ –∏–∑ UTC –≤ —Ä–µ–≥–∏–æ–Ω–∞–ª—å–Ω–æ–µ."""

        dep_region_code = (
            flight_plan.departure_region.code if flight_plan.departure_region else None
        )
        dest_region_code = (
            flight_plan.destination_region.code
            if flight_plan.destination_region
            else None
        )

        actual_departure_time = data.get("actual_departure_time")
        if (
            actual_departure_time
            and isinstance(actual_departure_time, time)
            and data.get("actual_departure_date")
        ):
            utc_dt = datetime.combine(
                data["actual_departure_date"], actual_departure_time
            )
            regional_dt = self._convert_utc_to_regional(utc_dt, dep_region_code)
            actual_departure_time = regional_dt.time()

        actual_arrival_time = data.get("actual_arrival_time")
        if (
            actual_arrival_time
            and isinstance(actual_arrival_time, time)
            and data.get("actual_arrival_date")
        ):
            utc_dt = datetime.combine(data["actual_arrival_date"], actual_arrival_time)
            regional_dt = self._convert_utc_to_regional(
                utc_dt, dest_region_code or dep_region_code
            )
            actual_arrival_time = regional_dt.time()

        return ActualFlight.objects.create(
            flight_plan=flight_plan,
            actual_departure_date=data.get("actual_departure_date"),
            actual_departure_time=actual_departure_time,
            actual_departure_point=data.get("actual_departure_point"),
            actual_arrival_date=data.get("actual_arrival_date"),
            actual_arrival_time=actual_arrival_time,
            actual_destination_point=data.get("actual_destination_point"),
        )

    def _create_actual_flight_with_duration(
        self, flight_plan: FlightPlan, data: dict[str, Any]
    ) -> ActualFlight:
        """–°–æ–∑–¥–∞–Ω–∏–µ –∑–∞–ø–∏—Å–∏ —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–ª–µ—Ç–∞ —Å —Ä–∞—Å—á–µ—Ç–æ–º –ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∏ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–µ–π –≤—Ä–µ–º–µ–Ω–∏."""

        dep_region_code = (
            flight_plan.departure_region.code if flight_plan.departure_region else None
        )
        dest_region_code = (
            flight_plan.destination_region.code
            if flight_plan.destination_region
            else None
        )

        actual_departure_time = data.get("actual_departure_time")
        if (
            actual_departure_time
            and data.get("dep_time_utc_raw")
            and data.get("actual_departure_date")
        ):
            utc_dt = datetime.combine(
                data["actual_departure_date"], actual_departure_time
            )
            regional_dt = self._convert_utc_to_regional(utc_dt, dep_region_code)
            actual_departure_time = regional_dt.time()

            actual_departure_date = regional_dt.date()
        else:
            actual_departure_date = data.get("actual_departure_date")

        actual_arrival_time = data.get("actual_arrival_time")
        if (
            actual_arrival_time
            and data.get("arr_time_utc_raw")
            and data.get("actual_arrival_date")
        ):
            utc_dt = datetime.combine(data["actual_arrival_date"], actual_arrival_time)
            regional_dt = self._convert_utc_to_regional(
                utc_dt, dest_region_code or dep_region_code
            )
            actual_arrival_time = regional_dt.time()

            actual_arrival_date = regional_dt.date()
        else:
            actual_arrival_date = data.get("actual_arrival_date")

        actual_duration = None
        if (
            actual_departure_date
            and actual_departure_time
            and actual_arrival_date
            and actual_arrival_time
        ):
            actual_duration = self._calculate_actual_flight_duration(
                actual_departure_date,
                actual_departure_time,
                actual_arrival_date,
                actual_arrival_time,
            )

        return ActualFlight.objects.create(
            flight_plan=flight_plan,
            actual_departure_date=actual_departure_date,
            actual_departure_time=actual_departure_time,
            actual_departure_point=data.get("actual_departure_point"),
            actual_arrival_date=actual_arrival_date,
            actual_arrival_time=actual_arrival_time,
            actual_destination_point=data.get("actual_destination_point"),
            actual_duration=actual_duration,
            flight_status="completed",
        )

    def _get_or_create_operator(self, operator_info: str) -> DroneOperator:
        return self._get_or_create_operator_cached(operator_info)

    def _get_or_create_drone_type(self, code: str) -> DroneType:
        return self._get_or_create_drone_type_cached(code)

    def _get_or_create_flight_zone(self, code: str) -> FlightZone:
        return self._get_or_create_flight_zone_cached(code)
